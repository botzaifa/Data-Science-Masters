{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_n52McdLcLx4"
   },
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "diqPBuhhcLx6"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un-comment the following when running for the first time:\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBe1VbsncLx8"
   },
   "source": [
    "# Sample Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8-w0lVJNcLx8"
   },
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\n",
    "Natural language processing (NLP) is a field of artificial intelligence that focuses on the interaction\n",
    "between computers and humans through natural language. The ultimate goal of NLP is to read, decipher,\n",
    "understand, and make sense of human language in a way that is both valuable and meaningful.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6Bf0lpDcLx8"
   },
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gELFG6dmcLx9"
   },
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word_tokenize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AjwtQnicLx9"
   },
   "source": [
    "# Lowercasing and Removing Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RTLv4UJJcLx9"
   },
   "outputs": [],
   "source": [
    "cleaned_words = [[re.sub(r'[^a-zA-Z0-9]', '', word.lower()) for word in sentence] for sentence in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXFE3t39cLx9"
   },
   "source": [
    "# Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "b-U6r_B4cLx9"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = [[word for word in sentence if word not in stop_words] for sentence in cleaned_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2GVXZUDcLx-"
   },
   "source": [
    "# Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HDRlWG7mcLx-"
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words = [[stemmer.stem(word) for word in sentence] for sentence in filtered_words]\n",
    "lemmatized_words = [[lemmatizer.lemmatize(word) for word in sentence] for sentence in filtered_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "164QuakWcLx-"
   },
   "source": [
    "# Printing Processed Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fxlOTHJKcLx-",
    "outputId": "cc8dce2a-849a-4c5e-ae4d-5813a1840167"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentences:\n",
      "\n",
      "Natural language processing (NLP) is a field of artificial intelligence that focuses on the interaction\n",
      "between computers and humans through natural language.\n",
      "The ultimate goal of NLP is to read, decipher,\n",
      "understand, and make sense of human language in a way that is both valuable and meaningful.\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Sentences:\")\n",
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2qCNgLbOcLx_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Sentences (Lemmatized):\n",
      "natural language processing  nlp  field artificial intelligence focus interaction computer human natural language \n",
      "ultimate goal nlp read  decipher  understand  make sense human language way valuable meaningful \n"
     ]
    }
   ],
   "source": [
    "print(\"Processed Sentences (Lemmatized):\")\n",
    "for sentence in lemmatized_words:\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
