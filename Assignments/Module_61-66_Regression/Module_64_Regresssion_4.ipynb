{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment (29th March) : Regression - 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. What is Lasso Regression, and how does it differ from other regression techniques?\n",
    "\n",
    "**ANS:** `Lasso Regression` is a linear regression method that includes a regularization term to penalize the absolute size of regression coefficients. It aims to minimize the residual sum of squares, with an additional constraint on the sum of the absolute values of the coefficients. It differs from other techniques like Ridge Regression, which penalizes squared coefficients and does not shrink any coefficients to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. What is the main advantage of using Lasso Regression in feature selection?\n",
    "\n",
    "**ANS:** The primary advantage of Lasso in feature selection is its `ability to shrink` irrelevant or less important feature coefficients to exactly zero, effectively removing them from the model. This leads to a simpler, more interpretable model with only significant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. How do you interpret the coefficients of a Lasso Regression model?\n",
    "\n",
    "**ANS:** In Lasso Regression, non-zero coefficients indicate important features in the model. A larger absolute coefficient implies a stronger association with the target variable. Zero coefficients mean that the model has removed these features, treating them as irrelevant to the target variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?\n",
    "\n",
    "**ANS:** The main tuning parameter in Lasso Regression is the regularization parameter, denoted as `lambda` (α or λ). Increasing lambda increases the penalty, which can shrink more coefficients to zero, thus enhancing sparsity. However, too high a lambda value may lead to underfitting. Adjusting lambda allows balancing model complexity with predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?\n",
    "\n",
    "**ANS:** `Yes`. Lasso can handle non-linear relationships by combining it with techniques like polynomial feature transformation. By transforming the features non-linearly and applying Lasso on the transformed features, the model can capture non-linear patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. What is the difference between Ridge Regression and Lasso Regression?\n",
    "\n",
    "**ANS:** The difference lies in the penalty term. Ridge Regression uses the `sum of squared coefficients` (L2 norm) for regularization, which reduces coefficient size without making them zero. Lasso uses the `sum of absolute values of coefficients` (L1 norm), which can shrink coefficients to zero, making it a useful technique for feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?\n",
    "\n",
    "**ANS:** `Yes`, Lasso can handle multicollinearity to some extent by selecting only one among correlated features and setting others to zero. This selection helps in reducing redundancy and enhancing model interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?\n",
    "\n",
    "**ANS:** The optimal lambda can be selected using `cross-validation`, such as K-fold cross-validation. This approach evaluates different lambda values to determine which one yields the best performance on a validation set, balancing bias and variance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
