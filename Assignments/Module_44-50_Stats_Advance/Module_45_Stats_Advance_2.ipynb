{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "920b2429",
   "metadata": {},
   "source": [
    "# Assignment (9th March) : Statistics Assignments - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15dbe63",
   "metadata": {},
   "source": [
    "### Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b22870",
   "metadata": {},
   "source": [
    "**ANS:** The Probability Mass Function (PMF) and Probability Density Function (PDF) are two fundamental concepts in probability theory and statistics, used to describe the distributions of discrete and continuous random variables, respectively.\n",
    "\n",
    "**`Probability Mass Function (PMF):`** The Probability Mass Function (PMF) is used for discrete random variables. It gives the probability that a discrete random variable is exactly equal to some value. Mathematically, for a discrete random variable \\( X \\), the PMF is denoted as \\( P(X = x) \\) or \\( p(x) \\).\n",
    "\n",
    "**Example:**\n",
    "Consider a fair six-sided die. Let \\( X \\) be the random variable representing the outcome of a single roll of the die. The PMF of \\( X \\) is:\n",
    "\n",
    "[ p(x) = \n",
    "\\begin{cases} \n",
    "\\frac{1}{6} & \\text{if } x \\in \\{1, 2, 3, 4, 5, 6\\} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "\n",
    "This means each of the six outcomes (1 through 6) has an equal probability of ( 1 / 6 ).\n",
    "\n",
    "\n",
    "**`Probability Density Function (PDF):`** The Probability Density Function (PDF) is used for continuous random variables. It describes the relative likelihood for the random variable to take on a given value. The PDF is denoted as \\( f(x) \\). Unlike the PMF, the PDF does not give probabilities directly; instead, the area under the PDF curve over an interval gives the probability that the random variable falls within that interval.\n",
    "\n",
    "**Example:**\n",
    "Consider a continuous random variable \\( X \\) that follows a normal distribution with mean \\( mu = 0 \\) and standard deviation \\( sigma = 1 \\). The PDF of \\( X \\) is:\n",
    "\n",
    "[ f(x) = (1 / sqrt{2pi}) (e^ {-{x^2}/{2}) ]\n",
    "\n",
    "This is the standard normal distribution. The probability that \\( X \\) falls within a particular range \\([a, b]\\) is given by the area under the curve of \\( f(x) \\) from \\( a \\) to \\( b \\):\n",
    "\n",
    "\n",
    "P(a =< X =< b) = b∫a (1 / sqrt{2π}) e^ (-x^2 / 2) dx\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319c5a65",
   "metadata": {},
   "source": [
    "### Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0f9c49",
   "metadata": {},
   "source": [
    "**ANS:** The Cumulative Distribution Function (CDF) is a fundamental concept in probability theory that describes the probability that a random variable takes on a value less than or equal to a specific value. It is applicable to both discrete and continuous random variables. The CDF provides a comprehensive way to describe the distribution of a random variable.\n",
    "\n",
    "Mathematically, for a random variable \\( X \\), the CDF, denoted as \\( F(x) \\), is defined as:\n",
    "\n",
    "`[ F(x) = P(X <= x) \\]`\n",
    "\n",
    "This means that \\( F(x) \\) gives the probability that the random variable \\( X \\) is less than or equal to \\( x \\).\n",
    "\n",
    "\n",
    "\n",
    "### Why CDF is Used:\n",
    "\n",
    "1. **`Complete Distribution Description`**: The CDF provides a complete description of the distribution of a random variable, including all probabilities associated with it.\n",
    "2. **`Probability Calculation`**: It is used to compute the probability that a random variable falls within a certain range. For example, \\( P(a <= X <= b) = F(b) - F(a) \\).\n",
    "3. **`Quantile Calculation`**: The CDF can be used to find quantiles, which are points in the distribution that correspond to specific probabilities.\n",
    "4. **`Comparison of Distributions`**: CDFs are useful for comparing different distributions. The CDF plots of different distributions can be compared to see which values are more likely in one distribution than another.\n",
    "5. **`CDF Inversion`**: The inverse of the CDF is used in sampling from a distribution. Given a probability, the inverse CDF gives the corresponding value of the random variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7659bc6f",
   "metadata": {},
   "source": [
    "### Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196c3a03",
   "metadata": {},
   "source": [
    "**ANS:** The normal distribution is characterized by two parameters: \n",
    "\n",
    "1. **Mean**: The mean is the central location parameter. It determines the center of the distribution. In a normal distribution, the mean, median, and mode are all equal and located at (mu).\n",
    "\n",
    "2. **Standard Deviation**: The standard deviation is a measure of the spread or dispersion of the distribution. It determines the width of the bell curve. A smaller (sigma) results in a steeper and narrower curve, while a larger (sigma) results in a flatter and wider curve.\n",
    "\n",
    "### Relationship Between Parameters and the Shape of the Distribution\n",
    "\n",
    "1. **Changing the Mean (mu)**:\n",
    "   - Shifts the entire distribution to the left or right along the horizontal axis.\n",
    "   - The shape of the distribution does not change; only the center changes.\n",
    "   - For example, if (mu) increases, the peak of the distribution moves to the right.\n",
    "\n",
    "2. **Changing the Standard Deviation (sigma)**:\n",
    "   - Affects the spread of the distribution.\n",
    "   - A larger (sigma) spreads the distribution out more, making it flatter and wider.\n",
    "   - A smaller (sigma) makes the distribution steeper and narrower.\n",
    "   - The area under the curve remains the same (equal to 1), as it represents the total probability.\n",
    "\n",
    "### Examples of Situations Where the Normal Distribution Might Be Used\n",
    "\n",
    "The normal distribution, also known as the Gaussian distribution, is widely used as a model in various fields due to its properties and the Central Limit Theorem. Here are some examples:\n",
    "\n",
    "1. **Height and Weight of Individuals**: The heights and weights of people in a population often follow a normal distribution, especially when considering a large sample size.\n",
    "\n",
    "2. **Test Scores**: Scores on standardized tests (e.g., SAT, IQ tests) are often modeled using a normal distribution.\n",
    "\n",
    "3. **Measurement Errors**: Measurement errors in scientific experiments tend to follow a normal distribution due to the aggregation of many small, independent errors.\n",
    "\n",
    "4. **Stock Prices and Financial Returns**: While stock prices themselves may not follow a normal distribution, the logarithm of stock prices or the returns over a short period can often be approximated by a normal distribution.\n",
    "\n",
    "5. **Quality Control**: In manufacturing, the variation in dimensions of machine parts often follows a normal distribution. This is used in quality control processes to determine acceptable ranges.\n",
    "\n",
    "6. **Biological Measurements**: Many biological measurements, such as blood pressure, enzyme activity, and reaction times, tend to be normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77142d6e",
   "metadata": {},
   "source": [
    "### Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ae453c",
   "metadata": {},
   "source": [
    "**ANS:** The normal distribution is critically important in statistics and many real-world applications for several reasons:\n",
    "\n",
    "1. **`Central Limit Theorem (CLT)`**: The CLT states that the sum (or average) of a large number of independent, identically distributed random variables tends toward a normal distribution, regardless of the original distribution of the variables. This makes the normal distribution a key tool for inference and hypothesis testing.\n",
    "\n",
    "2. **`Mathematical Properties`**: The normal distribution has convenient mathematical properties that facilitate analytical calculations. Many statistical methods and tests assume normality due to its simplicity and tractability.\n",
    "\n",
    "3. **`Descriptive Statistics`**: Many real-world phenomena naturally follow a normal distribution, making it a good model for many types of data. This allows for effective summarization and analysis of data.\n",
    "\n",
    "4. **`Probabilistic Interpretation`**: The normal distribution provides a clear probabilistic framework for predicting outcomes and understanding variability in data.\n",
    "\n",
    "5. **`Standardization`**: Data can be transformed into a standard normal distribution (mean = 0, standard deviation = 1) using z-scores, allowing for comparison across different datasets and variables.\n",
    "\n",
    "\n",
    "\n",
    "#### Real-Life Examples of Normal Distribution\n",
    "\n",
    "1. **`Human Heights`**:\n",
    "   - **Example**: The heights of adult men and women in a population tend to follow a normal distribution.\n",
    "   - **Importance**: This allows for the prediction of height-related statistics and informs areas such as clothing manufacturing and ergonomic design.\n",
    "\n",
    "2. **`IQ Scores`**:\n",
    "   - **Example**: IQ scores are designed to follow a normal distribution with a mean of 100 and a standard deviation of 15.\n",
    "   - **Importance**: This distribution allows for the assessment of cognitive abilities across a population and the identification of individuals with exceptionally high or low scores.\n",
    "\n",
    "3. **`Measurement Errors`**:\n",
    "   - **Example**: In scientific experiments, the errors in measurements due to instrument precision often follow a normal distribution.\n",
    "   - **Importance**: Understanding the distribution of measurement errors helps in estimating the accuracy and reliability of experimental results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178b67ee",
   "metadata": {},
   "source": [
    "### Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d527ab1a",
   "metadata": {},
   "source": [
    "**ANS:** The Bernoulli distribution is a discrete probability distribution for a random variable that has `only two possible outcomes`: success (usually coded as 1) and failure (usually coded as 0). It is the simplest type of discrete distribution and is used to model binary outcomes.\n",
    "\n",
    "- **`Example:`**\n",
    "Consider flipping a fair coin. Let (X) be the random variable representing the outcome, where heads (success) is coded as 1 and tails (failure) is coded as 0. The Bernoulli distribution for this scenario has (p = 0.5).\n",
    "\n",
    "**`Differences Between Bernoulli and Binomial Distributions:`**\n",
    "\n",
    "1. **Number of Trials**:\n",
    "   - **Bernoulli Distribution**: Models a single trial with two possible outcomes (success or failure).\n",
    "   - **Binomial Distribution**: Models the number of successes in \\( n \\) independent Bernoulli trials.\n",
    "\n",
    "\n",
    "2. **Parameters**:\n",
    "   - **Bernoulli Distribution**: Has a single parameter \\( p \\), which is the probability of success.\n",
    "   - **Binomial Distribution**: Has two parameters \\( n \\) (number of trials) and \\( p \\) (probability of success in each trial).\n",
    "\n",
    "\n",
    "3. **Support (Possible Values)**:\n",
    "   - **Bernoulli Distribution**: The random variable can take only two values: 0 (failure) and 1 (success).\n",
    "   - **Binomial Distribution**: The random variable can take any integer value from 0 to \\( n \\), representing the number of successes in \\( n \\) trials.\n",
    "\n",
    "\n",
    "4. **Application**:\n",
    "   - **Bernoulli Distribution**: Used for single trials or binary outcomes (e.g., flipping a coin once).\n",
    "   - **Binomial Distribution**: Used for multiple trials to count the number of successes (e.g., number of heads in 10 coin flips).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf64484",
   "metadata": {},
   "source": [
    "### Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308093ae",
   "metadata": {},
   "source": [
    "**ANS:** To find the probability that a randomly selected observation from a normally distributed dataset with a mean of 50 and a standard deviation of 10 is greater than 60, we can use the standard normal distribution (z-score) and standard normal distribution tables (or a calculator). The steps are as follows:\n",
    "\n",
    "1. **`Calculate the z-score`**:\n",
    "   The z-score is a measure of how many standard deviations an element is from the mean. The formula for the z-score is:\n",
    "\n",
    "   [ z = (X - mu) / (sigma)]\n",
    "\n",
    "   Where:\n",
    "   - (X) is the value of interest (60 in this case).\n",
    "   - (mu) is the mean of the distribution (50).\n",
    "   - (sigma) is the standard deviation of the distribution (10).\n",
    "\n",
    "   Substituting the values:\n",
    "\n",
    "   [ z = (60 - 50) / (10) = (10) / (10) = 1 ]\n",
    "\n",
    "2. **`Find the probability corresponding to the z-score`**:\n",
    "   We need to find \\( P(Z > 1) \\), where \\( Z \\) is a standard normal random variable.\n",
    "\n",
    "   Using standard normal distribution tables or a calculator, we find the cumulative probability for \\( Z <= 1 \\).\n",
    "\n",
    "   \\[\n",
    "   P(Z <= 1) approx 0.8413\n",
    "   \\]\n",
    "\n",
    "   This value represents the probability that a z-score is less than or equal to 1.\n",
    "\n",
    "3. **`Calculate the probability of (Z > 1)`**:\n",
    "   Since the total area under the standard normal distribution curve is 1, the probability that \\( Z \\) is greater than 1 is:\n",
    "\n",
    "   \\[\n",
    "   P(Z > 1) = 1 - P(Z <= 1)\n",
    "   \\]\n",
    "\n",
    "   Substituting the value from the table:\n",
    "\n",
    "   \\[\n",
    "   P(Z > 1) = 1 - 0.8413 = 0.1587\n",
    "   \\]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The probability that a randomly selected observation from this normally distributed dataset will be `greater than 60 is approximately 0.1587, or 15.87%.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0e61a",
   "metadata": {},
   "source": [
    "### Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f0109e",
   "metadata": {},
   "source": [
    "**ANS:** The uniform distribution is a type of probability distribution in which all outcomes are equally likely. Each value in a finite range is equally probable, and the distribution can be either discrete or continuous.\n",
    "\n",
    "1. **`Discrete Uniform Distribution:`** A discrete uniform distribution is defined over a set of (n) distinct outcomes, each of which has an equal probability. \n",
    "\n",
    "**Example:**\n",
    "Consider rolling a fair six-sided die. The possible outcomes are {1, 2, 3, 4, 5, 6}, and each outcome has an equal probability of ((1) / (6)).\n",
    "\n",
    "\n",
    "2. **`Continuous Uniform Distribution:`** A continuous uniform distribution is defined over a continuous range (a, b), where every value within this range is equally likely.\n",
    "\n",
    "**Example:**\n",
    "Consider a random variable (X) that represents the time (in minutes) a person waits for a bus that arrives at a bus stop every hour. The waiting time is uniformly distributed between 0 and 60 minutes.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56394791",
   "metadata": {},
   "source": [
    "### Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2d9811",
   "metadata": {},
   "source": [
    "**ANS:** The z score, also known as the standard score, measures how many standard deviations an individual data point is from the mean of a dataset. It is a way to standardize data points within different distributions, allowing for comparison across different scales.\n",
    "\n",
    "The formula for calculating the z score of a data point (x) is:\n",
    "\n",
    "[z = (x - mu) / (sigma)]\n",
    "\n",
    "Where:\n",
    "- (x) is the value of the data point.\n",
    "- (mu) is the mean of the dataset.\n",
    "- (sigma) is the standard deviation of the dataset.\n",
    "\n",
    "**`Importance of the Z Score:`**\n",
    "\n",
    "1. **Standardization**: The z score standardizes data points, allowing for comparison between different datasets or distributions. This is especially useful when dealing with data measured on different scales or units.\n",
    "\n",
    "2. **Identifying Outliers**: Z scores help in identifying outliers in the data. Data points with a z score greater than 3 or less than -3 are often considered outliers, as they lie far from the mean.\n",
    "\n",
    "3. **Normal Distribution**: In a normal distribution, z scores provide a way to determine the probability of a data point occurring within a certain range. This is useful in statistical analysis and hypothesis testing.\n",
    "\n",
    "4. **Comparing Scores Across Different Distributions**: Z scores allow for comparison of scores from different distributions by converting them to a common scale. For example, comparing SAT scores and ACT scores, which are on different scales, can be done using z scores.\n",
    "\n",
    "5. **Probabilistic Interpretation**: Z scores are used to calculate probabilities and percentiles in a standard normal distribution. This is helpful in various applications, such as quality control, finance, and social sciences.\n",
    "\n",
    "6. **Hypothesis Testing**: In hypothesis testing, z scores are used to determine how far away a sample mean is from the population mean under the null hypothesis. This helps in making decisions about the validity of the null hypothesis.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6ae727",
   "metadata": {},
   "source": [
    "### Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb922d6",
   "metadata": {},
   "source": [
    "**ANS:** The Central Limit Theorem (CLT) is a fundamental theorem in statistics that describes the characteristics of the sampling distribution of the sample mean. The theorem states that, given a sufficiently large sample size, the sampling distribution of the sample mean will be approximately normally distributed, regardless of the original distribution of the population from which the sample is drawn. This holds true as long as the population has a finite variance.\n",
    "\n",
    "\n",
    "\n",
    "**`Significance of the Central Limit Theorem:`**\n",
    "\n",
    "1. **Foundation for Inferential Statistics**: The CLT provides the theoretical foundation for making inferences about population parameters using sample statistics. It allows us to use sample data to estimate population parameters and make predictions.\n",
    "\n",
    "2. **Approximation of Distribution**: The CLT justifies the use of the normal distribution as an approximation for the distribution of the sample mean, even when the underlying population distribution is not normal. This is particularly useful when dealing with non-normally distributed data.\n",
    "\n",
    "3. **Simplification of Analysis**: Because the sample mean follows a normal distribution for large sample sizes, many statistical procedures and tests (such as confidence intervals and hypothesis tests) that assume normality can be applied, simplifying the analysis.\n",
    "\n",
    "4. **Applications in Real-World Problems**: The CLT is widely used in various fields, such as economics, engineering, social sciences, and natural sciences, where it helps in analyzing and interpreting data.\n",
    "\n",
    "5. **Law of Large Numbers**: The CLT complements the Law of Large Numbers, which states that as the sample size increases, the sample mean converges to the population mean. Together, these theorems provide a robust framework for understanding the behavior of sample statistics.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac1e0da",
   "metadata": {},
   "source": [
    "### Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ea8250",
   "metadata": {},
   "source": [
    "**ANS:** The Central Limit Theorem (CLT) makes several key assumptions that must be satisfied for the theorem to hold true. These assumptions are crucial for ensuring that the sampling distribution of the sample mean approximates a normal distribution as the sample size becomes large.\n",
    "\n",
    "1. **`Independence`**:   The sampled observations must be independent of each other. This means that the outcome of one observation should not affect the outcome of another. In practice, this is often achieved by random sampling.\n",
    "\n",
    "\n",
    "2. **`Identically Distributed`**:  The sampled observations should be drawn from the same population, meaning they should be identically distributed. This implies that each observation comes from the same probability distribution with the same mean (mu) and variance (sigma^2).\n",
    "\n",
    "\n",
    "3. **`Finite Variance`**:  The population from which the sample is drawn must have a finite variance (sigma^2 < infty). If the variance is infinite, the CLT does not apply.\n",
    "\n",
    "\n",
    "4. **`Sample Size`**:  The sample size (n) should be sufficiently large. While there is no strict rule for what constitutes a \"large\" sample size, a common guideline is (n >= 30). However, the required sample size can vary depending on the shape of the underlying population distribution:\n",
    "     - If the population distribution is approximately normal, even smaller sample sizes can suffice.\n",
    "     - If the population distribution is heavily skewed or has heavy tails, larger sample sizes are necessary to achieve a normal approximation.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
