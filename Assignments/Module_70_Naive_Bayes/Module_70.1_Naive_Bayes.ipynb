{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment (9th April) : Naive Bayes - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. What is Bayes' theorem?\n",
    "\n",
    "**ANS:** `Bayes' theorem` is a fundamental concept in probability theory that describes how to update the probability of a hypothesis (event) based on new evidence. It relates the conditional and marginal probabilities of random events, allowing for calculating the probability of an event given prior knowledge of related events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. What is the formula for Bayes' theorem?\n",
    "\n",
    "**ANS:** The `formula for Bayes' theorem` is:\n",
    "\\[\n",
    "P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n",
    "\\]\n",
    "where:\n",
    "- \\( P(A|B) \\): Probability of event \\( A \\) occurring given that \\( B \\) is true (posterior probability).\n",
    "- \\( P(B|A) \\): Probability of event \\( B \\) occurring given that \\( A \\) is true (likelihood).\n",
    "- \\( P(A) \\): Probability of event \\( A \\) occurring (prior probability).\n",
    "- \\( P(B) \\): Probability of event \\( B \\) occurring (marginal probability)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. How is Bayes' theorem used in practice?\n",
    "\n",
    "**ANS:** In practice, Bayes' theorem is used in a variety of fields, such as:\n",
    "1. `Spam filtering`: Determining if an email is spam based on the occurrence of certain keywords.\n",
    "2. `Medical diagnosis`: Calculating the probability of a disease given test results.\n",
    "3. `Machine learning (Naive Bayes)`: Classifying data points based on prior knowledge and observed features.\n",
    "4. `Weather prediction`: Updating weather predictions based on new data or events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
    "\n",
    "**ANS:** Bayes' theorem is based on conditional probability and provides a `way to reverse the conditioning`. It calculates the probability of an event \\( A \\) given another event \\( B \\), even if \\( P(A|B) \\) is initially unknown, by using the probability of \\( B \\) given \\( A \\). Conditional probability, in general, describes the probability of one event occurring given the occurrence of another event, while Bayes' theorem formalizes how to update beliefs based on evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "\n",
    "**ANS:** Choosing a Naive Bayes classifier depends on the nature of the data:\n",
    "- `Gaussian Naive Bayes`: Suitable for continuous data, assuming a normal distribution of features.\n",
    "- `Multinomial Naive Bayes`: Commonly used for text classification where features represent counts, such as word counts in documents.\n",
    "- `Bernoulli Naive Bayes`: Ideal for binary data, often used in text classification where features are binary (e.g., the presence or absence of words)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Assignment\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class:\n",
    "\n",
    "| Class | X1=1 | X1=2 | X1=3 | X2=1 | X2=2 | X2=3 | X2=4 |\n",
    "|-------|----|----|----|----|----|----|----|\n",
    "| A | 3 | 3 | 4 |  4 |  3 |  3 |  3 | \n",
    "| B  | 2  | 2 |  1 |  2 |  2 |  2 |  3 | \n",
    "\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance to belong to?\n",
    "\n",
    "\n",
    "**ANS:** Given the frequency table for each feature value and the classes \\( A \\) and \\( B \\), we can use Naive Bayes to classify the new instance with \\( X1 = 3 \\) and \\( X2 = 4 \\). Assuming equal prior probabilities for each class, weâ€™ll calculate the probability of each class given the feature values and select the class with the highest probability.\n",
    "\n",
    "`Step-by-Step Solution`:\n",
    "\n",
    "1. **Calculate Likelihoods** for \\( X1 = 3 \\) and \\( X2 = 4 \\) for each class.\n",
    "   \n",
    "   From the table:\n",
    "   - **Class A**:\n",
    "     - \\( P(X1=3 | A) = \\frac{4}{10} = 0.4 \\)\n",
    "     - \\( P(X2=4 | A) = \\frac{3}{10} = 0.3 \\)\n",
    "     - Since \\( P(A) = 0.5 \\) (equal prior), we get:\n",
    "       \\[\n",
    "       P(A | X1=3, X2=4) \\propto P(X1=3 | A) \\cdot P(X2=4 | A) \\cdot P(A) = 0.4 \\times 0.3 \\times 0.5 = 0.06\n",
    "       \\]\n",
    "\n",
    "   - **Class B**:\n",
    "     - \\( P(X1=3 | B) = \\frac{1}{7} \\approx 0.143 \\)\n",
    "     - \\( P(X2=4 | B) = \\frac{3}{7} \\approx 0.429 \\)\n",
    "     - Using \\( P(B) = 0.5 \\), we get:\n",
    "       \\[\n",
    "       P(B | X1=3, X2=4) \\propto P(X1=3 | B) \\cdot P(X2=4 | B) \\cdot P(B) \\approx 0.143 \\times 0.429 \\times 0.5 \\approx 0.0306\n",
    "       \\]\n",
    "\n",
    "2. **Compare Posterior Probabilities**:\n",
    "   - \\( P(A | X1=3, X2=4) \\approx 0.06 \\)\n",
    "   - \\( P(B | X1=3, X2=4) \\approx 0.0306 \\)\n",
    "\n",
    "3. **Prediction**:\n",
    "   Since \\( P(A | X1=3, X2=4) > P(B | X1=3, X2=4) \\), the **Naive Bayes classifier would predict the new instance belongs to class A**."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
