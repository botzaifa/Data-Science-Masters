{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment (2nd April) : Logistic Regression - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. What is the purpose of grid search CV in machine learning, and how does it work?\n",
    "**ANS**: Grid Search Cross-Validation (CV) is used to find the `optimal hyperparameters for a model` by exhaustively testing all specified parameter combinations. It performs cross-validation for each combination and selects the one with the best performance, ensuring the model is fine-tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Describe the difference between grid search CV and randomized search CV, and when might you choose one over the other?\n",
    "\n",
    "**ANS**: \n",
    "\n",
    "- `Grid Search CV` tests all possible parameter combinations, which can be time-consuming.\n",
    "\n",
    "- `Randomized Search CV` samples a fixed number of random combinations from the parameter space, making it faster and more efficient.\n",
    "\n",
    "- `When to choose`: Use Grid Search for smaller parameter spaces and Randomized Search for larger spaces or when computational resources are limited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. What is data leakage, and why is it a problem in machine learning? Provide an example.\n",
    "\n",
    "**ANS**: Data leakage occurs when `information from outside the training dataset influences the model`, causing it to learn patterns that won’t be available in real-world data. This leads to overly optimistic performance during training but poor generalization.\n",
    "\n",
    "`Example`: Including future stock prices when training a model to predict future trends results in a model that “knows” the answer ahead of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. How can you prevent data leakage when building a machine learning model?\n",
    "\n",
    "**ANS**: \n",
    "- `Use proper train-test splits`: Ensure no data from the test set is used in training.\n",
    "\n",
    "- `Apply preprocessing within cross-validation`: Scale or transform data after the split to avoid contaminating training data.\n",
    "\n",
    "- `Check feature correlations`: Avoid features that may indirectly contain target information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. What is a confusion matrix, and what does it tell you about the performance of a classification model?\n",
    "\n",
    "**ANS**: A confusion matrix is a `table that shows the actual vs. predicted classifications`, organized into:\n",
    "\n",
    "- True Positives (TP)\n",
    "- True Negatives (TN) \n",
    "- False Positives (FP) \n",
    "- False Negatives (FN) \n",
    "  \n",
    "It helps visualize where the model makes correct predictions versus errors, providing insight into specific types of misclassification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Explain the difference between precision and recall in the context of a confusion matrix.\n",
    "\n",
    "**ANS**: \n",
    "- `Precision`: The proportion of true positive predictions among all positive predictions, calculated as TP/(TP+FP). It measures the accuracy of positive predictions. \n",
    "\n",
    "- `Recall`: The proportion of true positives among all actual positives, calculated as TP/(TP+FN). It measures the model’s ability to identify actual positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. How can you interpret a confusion matrix to determine which types of errors your model is making?\n",
    "\n",
    "**ANS**: Examine the FP and FN values:\n",
    "\n",
    "- `High FP` indicates the model often incorrectly classifies negatives as positives.\n",
    "\n",
    "- `High FN` suggests the model fails to capture many actual positives. By analyzing these values, you can identify if the model is biased towards one class or if it struggles to recognize certain types of instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. What are some common metrics that can be derived from a confusion matrix, and how are they calculated?\n",
    "\n",
    "**ANS**:\n",
    "\n",
    "- `Accuracy`: (TP+TN)/Total, the overall correctness of predictions.\n",
    "- `Precision`: TP/(TP+FP), accuracy among predicted positives.\n",
    "- `Recall`: TP/(TP+FN), proportion of actual positives identified.\n",
    "- `F1 Score`: Harmonic mean of precision and recall, useful for imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. What is the relationship between the accuracy of a model and the values in its confusion matrix?\n",
    "\n",
    "**ANS**: Accuracy depends on the `sum of correct predictions` (TP + TN) in the confusion matrix relative to the total predictions. However, accuracy alone can be misleading, especially with imbalanced data, where high accuracy may not reflect good performance across all classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. How can you use a confusion matrix to identify potential biases or limitations in your machine learning model?\n",
    "\n",
    "**ANS**: The confusion matrix reveals if a model is biased towards one class (e.g., high FN or FP rates for a specific class) or struggles with certain categories. This insight can highlight limitations, such as underperforming on minority classes, helping you adjust the model or consider techniques like class weighting or re-sampling."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
