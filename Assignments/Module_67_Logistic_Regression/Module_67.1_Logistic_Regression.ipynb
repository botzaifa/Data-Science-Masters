{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment (1st April) : Logistic Regression - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Explain the difference between linear regression and logistic regression models. Provide an example of a scenario where logistic regression would be more appropriate.\n",
    "\n",
    "**ANS**: The differences are as follows:\n",
    "\n",
    "- `Linear Regression` predicts continuous values based on the input variables by minimizing the mean squared error.\n",
    "- `Logistic Regression` predicts the probability of categorical outcomes, typically binary (e.g., yes/no) values, using a sigmoid function to map predicted values between 0 and 1.\n",
    "\n",
    "`Example`: Logistic regression is more appropriate for classifying emails as spam or not spam, where the target variable is binary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. What is the cost function used in logistic regression, and how is it optimized?\n",
    "\n",
    "**ANS**: The cost function in logistic regression is `log loss` (or binary cross-entropy), which penalizes incorrect predictions by calculating the negative log-likelihood of the predicted probabilities. Optimization is usually done through `gradient descent`, minimizing log loss to find the best-fit parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Explain the concept of regularization in logistic regression and how it helps prevent overfitting.\n",
    "\n",
    "**ANS:** Regularization adds a penalty to the logistic regression cost function to prevent overfitting:\n",
    "\n",
    "- `L2 Regularization` (Ridge) penalizes the square of the coefficients, shrinking their values.\n",
    "- `L1 Regularization` (Lasso) penalizes the absolute values of the coefficients, driving some to zero for feature selection. Regularization reduces the modelâ€™s complexity, preventing it from fitting noise in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. What is the ROC curve, and how is it used to evaluate the performance of the logistic regression model?\n",
    "\n",
    "**ANS:** The ROC curve (Receiver Operating Characteristic) `plots the True Positive Rate against the False Positive Rate` across different threshold values. The area under the ROC curve (AUC) measures model performance, with values closer to 1 indicating better classification ability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. What are some common techniques for feature selection in logistic regression? How do these techniques help improve the model's performance?\n",
    "\n",
    "**ANS:** The techniques that may help us improve the model's performance are:\n",
    "- `Recursive Feature Elimination (RFE)`: Iteratively removes less important features based on model coefficients.\n",
    "- `Lasso Regularization (L1)`: Shrinks less important features to zero.\n",
    "- `Chi-Square Test`: Selects features based on their association with the target variable. These techniques reduce irrelevant features, simplify the model, and improve generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. How can you handle imbalanced datasets in logistic regression? What are some strategies for dealing with class imbalance?\n",
    "\n",
    "**ANS:** We can handle it using these stratergies:\n",
    "- `Resampling Techniques`: Use oversampling (e.g., SMOTE) or undersampling to balance classes.\n",
    "- `Class Weights Adjustment`: Assign higher weights to the minority class to make the model focus more on it.\n",
    "- `Threshold Adjustment`: Adjust the probability threshold to improve sensitivity for the minority class. These methods help the model better capture minority class characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. Can you discuss some common issues and challenges that may arise when implementing logistic regression, and how they can be addressed? For example, what can be done if there is multicollinearity among the independent variables?\n",
    "\n",
    "**ANS:** Common Issues and Challenges that may arise are:\n",
    "\n",
    "- `Multicollinearity`: Highly correlated predictors can lead to unreliable coefficients. Solution: Use techniques like Variance Inflation Factor (VIF) to detect multicollinearity and apply L2 regularization or remove correlated features.\n",
    "- `Outliers`: Outliers can skew model results. Solution: Detect and remove or transform outliers.\n",
    "- `Overfitting`: The model may fit noise in the data. Solution: Use regularization to reduce complexity."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
