{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDKUJmE9FZ3e"
   },
   "source": [
    "# Observe results before and after applying Transfer Learning.\n",
    "\n",
    "Transfer learning is a research problem in machine learning & deep learning that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem. For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks.So, in transfer learning your previous learning helps you to understand the new concept or learning. In transfer learning we use pre-trained model & we make some modification on that to make a new model.\n",
    "\n",
    "So, here we will create a hand writing classifier by MNIST data then we will modify this model to predict a given number is odd or even by the help of transfer learning. Then we will compare them not using transfer learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58hizcaNFuiO"
   },
   "source": [
    "# Now first creating a Model which can classify MNIST handwriting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AuWkhnCBHwVb",
    "outputId": "490dee88-d89a-42b0-93c1-3acfbdc5376b"
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BVGQ8k1eH1Lr"
   },
   "outputs": [],
   "source": [
    "# Loading the data of MNIST handwritten\n",
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KuvvPZvnH6xM"
   },
   "outputs": [],
   "source": [
    "# Creating layer of model\n",
    "tf.random.set_seed(42)  #For getting similar output (optional)\n",
    "np.random.seed(42)  #For getting similar output (optional)\n",
    "\n",
    "LAYERS = [ tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")]\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential(LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZH0pj2szICdn"
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUqaISXyIGR6",
    "outputId": "849bb778-f20d-4fd3-abb9-bbef4540fd96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 300)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AbtPHy74ILi_",
    "outputId": "7d6b6edc-a01d-440d-857d-c97ea03afcdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 - 6s - loss: 1.5417 - accuracy: 0.5967 - val_loss: 0.9407 - val_accuracy: 0.8024 - 6s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "1719/1719 - 6s - loss: 0.7444 - accuracy: 0.8224 - val_loss: 0.5932 - val_accuracy: 0.8540 - 6s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "1719/1719 - 6s - loss: 0.5451 - accuracy: 0.8571 - val_loss: 0.4782 - val_accuracy: 0.8738 - 6s/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "1719/1719 - 5s - loss: 0.4639 - accuracy: 0.8737 - val_loss: 0.4198 - val_accuracy: 0.8882 - 5s/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "1719/1719 - 5s - loss: 0.4189 - accuracy: 0.8835 - val_loss: 0.3850 - val_accuracy: 0.8958 - 5s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "1719/1719 - 4s - loss: 0.3897 - accuracy: 0.8909 - val_loss: 0.3618 - val_accuracy: 0.9008 - 4s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "1719/1719 - 5s - loss: 0.3686 - accuracy: 0.8958 - val_loss: 0.3438 - val_accuracy: 0.9054 - 5s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "1719/1719 - 6s - loss: 0.3524 - accuracy: 0.9003 - val_loss: 0.3296 - val_accuracy: 0.9104 - 6s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "1719/1719 - 5s - loss: 0.3392 - accuracy: 0.9037 - val_loss: 0.3196 - val_accuracy: 0.9118 - 5s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "1719/1719 - 6s - loss: 0.3285 - accuracy: 0.9063 - val_loss: 0.3096 - val_accuracy: 0.9142 - 6s/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Lets train the model\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GuyAC1_PIP_1"
   },
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "# model.save(\"pretrained_mnist_model.h5\")\n",
    "model.save(\"pretrained_mnist_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKuYBy26Iy0L"
   },
   "source": [
    "# Now Lets create a model which can  predict a given number is odd or even without having Transfer learning technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AkU0whkoIjv7"
   },
   "outputs": [],
   "source": [
    "# Making the label as an even or odd category from numbers where even is 1 and odd is 0\n",
    "\n",
    "def update_even_odd_labels(labels):\n",
    "  for idx, label in enumerate(labels):\n",
    "    labels[idx] = np.where(label % 2 == 0, 1, 0)\n",
    "  return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "l7shWWsyJtWG"
   },
   "outputs": [],
   "source": [
    "y_train_bin, y_test_bin, y_valid_bin = update_even_odd_labels([y_train, y_test, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4BZ2SV1fJyxy"
   },
   "outputs": [],
   "source": [
    "# Creating layer of model\n",
    "tf.random.set_seed(42)  #For getting similar output (optional)\n",
    "np.random.seed(42)  #For getting similar output (optional)\n",
    "\n",
    "LAYERS = [ tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dense(2, activation=\"softmax\")]  # Here I have just used 2 output layers cz, our output would be 0 or 1\n",
    "\n",
    "\n",
    "model_1 = tf.keras.models.Sequential(LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9li_zgEgKd3z",
    "outputId": "88a1f87e-4f43-42b5-fb88-8e0e86d8a3e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 300)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 265802 (1.01 MB)\n",
      "Trainable params: 265802 (1.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling new model\n",
    "model_1.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bF8aLsfsK8w6",
    "outputId": "f1197a99-7049-4c67-d6b1-4a5d2e28e5fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 - 6s - loss: 0.4486 - accuracy: 0.7950 - val_loss: 0.3346 - val_accuracy: 0.8620 - 6s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "1719/1719 - 5s - loss: 0.3172 - accuracy: 0.8657 - val_loss: 0.2832 - val_accuracy: 0.8830 - 5s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "1719/1719 - 5s - loss: 0.2813 - accuracy: 0.8845 - val_loss: 0.2530 - val_accuracy: 0.9026 - 5s/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "1719/1719 - 5s - loss: 0.2564 - accuracy: 0.8986 - val_loss: 0.2308 - val_accuracy: 0.9126 - 5s/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "1719/1719 - 5s - loss: 0.2358 - accuracy: 0.9090 - val_loss: 0.2119 - val_accuracy: 0.9232 - 5s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "1719/1719 - 5s - loss: 0.2184 - accuracy: 0.9179 - val_loss: 0.1955 - val_accuracy: 0.9316 - 5s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "1719/1719 - 6s - loss: 0.2029 - accuracy: 0.9258 - val_loss: 0.1819 - val_accuracy: 0.9398 - 6s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "1719/1719 - 5s - loss: 0.1895 - accuracy: 0.9317 - val_loss: 0.1698 - val_accuracy: 0.9442 - 5s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "1719/1719 - 5s - loss: 0.1776 - accuracy: 0.9378 - val_loss: 0.1600 - val_accuracy: 0.9486 - 5s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "1719/1719 - 5s - loss: 0.1673 - accuracy: 0.9415 - val_loss: 0.1514 - val_accuracy: 0.9516 - 5s/epoch - 3ms/step\n",
      "Runtime of the program is 50.24093818664551\n"
     ]
    }
   ],
   "source": [
    "# now training & calculating the training time.\n",
    "\n",
    "# starting time\n",
    "start = time.time()\n",
    "\n",
    "history = model_1.fit(X_train, y_train_bin, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid_bin), verbose=2)\n",
    "\n",
    "#ending time\n",
    "end = time.time()\n",
    "\n",
    "# total time taken\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4sQ0wqFL-t5"
   },
   "source": [
    "## Conclusion:  \n",
    "Runtime of the program is 50.24 sec & val_accuracy: 0.9516"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWXlrZ5DMO11"
   },
   "source": [
    "# Now Let's create the same model which can predict a given number is odd or even with having Transfer learning technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "m7SzdvRhLr31"
   },
   "outputs": [],
   "source": [
    "# Loading pre-trained model\n",
    "# pretrained_mnist_model = tf.keras.models.load_model(\"pretrained_mnist_model.h5\")\n",
    "pretrained_mnist_model = tf.keras.models.load_model(\"pretrained_mnist_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WOil-wj8MjoK",
    "outputId": "f040fb36-3bf5-4ddd-9e54-df877d519476"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 300)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_mnist_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gji2FRPFMm2q",
    "outputId": "72dc6744-ec56-43ff-db31-f203c51e532f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten: True\n",
      "dense: True\n",
      "leaky_re_lu: True\n",
      "dense_1: True\n",
      "leaky_re_lu_1: True\n",
      "dense_2: True\n"
     ]
    }
   ],
   "source": [
    "# Checking layers are trainable or not\n",
    "for layer in pretrained_mnist_model.layers:\n",
    "  print(f\"{layer.name}: {layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mKcteCVeMpx9",
    "outputId": "e08eb94c-2f08-4cb1-96a2-ae1bbb5bb1d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten_2: False\n",
      "dense_7: False\n",
      "leaky_re_lu_4: False\n",
      "dense_8: False\n",
      "leaky_re_lu_5: False\n"
     ]
    }
   ],
   "source": [
    "# # Lets make them false or non trainable except last one\n",
    "# for layer in pretrained_mnist_model.layers[:-1]:\n",
    "#   layer.trainable = False\n",
    "#   print(f\"{layer.name}: {layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten: False\n",
      "dense: False\n",
      "leaky_re_lu: False\n",
      "dense_1: False\n",
      "leaky_re_lu_1: False\n"
     ]
    }
   ],
   "source": [
    "# Lets make them false or non trainable except last one\n",
    "for layer in pretrained_mnist_model.layers[:-1]:\n",
    "  layer.trainable = False\n",
    "  print(f\"{layer.name}: {layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DNFQCPjQMtcp",
    "outputId": "08a043c3-d10c-4dab-c87f-ba81c91fe2d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten_2: False\n",
      "dense_7: False\n",
      "leaky_re_lu_4: False\n",
      "dense_8: False\n",
      "leaky_re_lu_5: False\n",
      "dense_9: True\n"
     ]
    }
   ],
   "source": [
    "# for layer in pretrained_mnist_model.layers:\n",
    "#   print(f\"{layer.name}: {layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten: False\n",
      "dense: False\n",
      "leaky_re_lu: False\n",
      "dense_1: False\n",
      "leaky_re_lu_1: False\n",
      "dense_2: True\n"
     ]
    }
   ],
   "source": [
    "for layer in pretrained_mnist_model.layers:\n",
    "  print(f\"{layer.name}: {layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "_lxFF8DFMwr-"
   },
   "outputs": [],
   "source": [
    "# Now make a model using that one\n",
    "lower_pretrained_layers = pretrained_mnist_model.layers[:-1]\n",
    "\n",
    "new_model = tf.keras.models.Sequential(lower_pretrained_layers)\n",
    "new_model.add(\n",
    "    tf.keras.layers.Dense(2, activation=\"softmax\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 300)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 265802 (1.01 MB)\n",
      "Trainable params: 202 (808.00 Byte)\n",
      "Non-trainable params: 265600 (1.01 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "v9E8aIpWM614"
   },
   "outputs": [],
   "source": [
    "# Making the label as an even or odd category from numbers where even is 1 and odd is 0\n",
    "\n",
    "def update_even_odd_labels(labels):\n",
    "  for idx, label in enumerate(labels):\n",
    "    labels[idx] = np.where(label % 2 == 0, 1, 0)\n",
    "  return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "WudW1HNSNDyG"
   },
   "outputs": [],
   "source": [
    "y_train_bin, y_test_bin, y_valid_bin = update_even_odd_labels([y_train, y_test, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling new model\n",
    "new_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 - 4s - loss: 0.4332 - accuracy: 0.8106 - val_loss: 0.3448 - val_accuracy: 0.8480 - 4s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "1719/1719 - 4s - loss: 0.3490 - accuracy: 0.8460 - val_loss: 0.3230 - val_accuracy: 0.8592 - 4s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "1719/1719 - 4s - loss: 0.3332 - accuracy: 0.8553 - val_loss: 0.3107 - val_accuracy: 0.8662 - 4s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "1719/1719 - 4s - loss: 0.3231 - accuracy: 0.8606 - val_loss: 0.3027 - val_accuracy: 0.8720 - 4s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "1719/1719 - 4s - loss: 0.3155 - accuracy: 0.8643 - val_loss: 0.2961 - val_accuracy: 0.8774 - 4s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "1719/1719 - 4s - loss: 0.3097 - accuracy: 0.8674 - val_loss: 0.2909 - val_accuracy: 0.8806 - 4s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "1719/1719 - 4s - loss: 0.3047 - accuracy: 0.8699 - val_loss: 0.2868 - val_accuracy: 0.8818 - 4s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "1719/1719 - 4s - loss: 0.3006 - accuracy: 0.8726 - val_loss: 0.2831 - val_accuracy: 0.8808 - 4s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "1719/1719 - 4s - loss: 0.2967 - accuracy: 0.8744 - val_loss: 0.2810 - val_accuracy: 0.8818 - 4s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "1719/1719 - 4s - loss: 0.2936 - accuracy: 0.8762 - val_loss: 0.2773 - val_accuracy: 0.8830 - 4s/epoch - 2ms/step\n",
      "Runtime of the program is 42.070425271987915\n"
     ]
    }
   ],
   "source": [
    "# starting time\n",
    "start = time.time()\n",
    "\n",
    "history = new_model.fit(X_train, y_train_bin, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid_bin), verbose=2)\n",
    "\n",
    "#ending time\n",
    "end = time.time()\n",
    "print(f\"Runtime of the program is {end - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdfAWt39PLD6"
   },
   "source": [
    "# Conclusion:\n",
    "Runtime of the program is 42.07 sec & val_accuracy: 0.8830"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76kiGFCePYEP"
   },
   "source": [
    "# Comparison:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Transfer learning:\n",
    "- Runtime of the program is 50.24 sec \n",
    "- val_accuracy: 0.9516\n",
    "\n",
    "## With Transfer Learning:\n",
    "- Runtime of the program is 42.07 sec\n",
    "- val_accuracy: 0.8830\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can we have transfer learning output is pretty close to actual accuracy, although we are just training 202 parameters. So, if we increase the epochs then the accuracy would be high. Now it is taking same time but in big problem it may take less time with compare to Without Transfer learning."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
